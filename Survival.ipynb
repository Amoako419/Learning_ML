{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (623, 15)\n",
      "Test data shape: (268, 15)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Splitting the full dataset into the training and testing datasets\n",
    "train_data, test_data = train_test_split(titanic_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Printing out the shapes of the datasets\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       111\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       1.00      1.00      1.00       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [  0 111]]\n",
      "Accuracy Score:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# One-hot encode categorical variables using pandas get_dummies\n",
    "titanic_preprocessed = pd.get_dummies(titanic_df, columns=['sex', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'], drop_first=True)\n",
    "\n",
    "# Handle any NaN values by filling them with the mean of the column\n",
    "titanic_preprocessed = titanic_preprocessed.fillna(titanic_preprocessed.mean())\n",
    "\n",
    "# Split the preprocessed dataset into the training and testing datasets with a 70%-30% split\n",
    "train_data, test_data = train_test_split(titanic_preprocessed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Separate the target variable (\"survived\") from the rest of the training data\n",
    "x_train = train_data.drop(\"survived\", axis=1)\n",
    "y_train = train_data[\"survived\"]\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "\n",
    "# Training the Logistic Regression model\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "#The test dataset\n",
    "x_test =test_data.drop(\"survived\", axis=1)\n",
    "y_test = test_data[\"survived\"]\n",
    "\n",
    "# Using the model to make predictions on the testing dataset\n",
    "predictions = logreg.predict(x_test) \n",
    "\n",
    "# Displaying metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions)) \n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))  \n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH MinmaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78       157\n",
      "           1       0.74      0.46      0.57       111\n",
      "\n",
      "    accuracy                           0.71       268\n",
      "   macro avg       0.72      0.67      0.67       268\n",
      "weighted avg       0.72      0.71      0.69       268\n",
      "\n",
      "Accuracy Score:\n",
      "0.7089552238805971\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop non-numeric columns for simplicity\n",
    "titanic_df = titanic_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Handle any NaN values by filling them with the mean of the column\n",
    "titanic_df = titanic_df.fillna(titanic_df.mean())\n",
    "\n",
    "# TODO: Use MinMaxScaler to scale the numeric features into a standard range\n",
    "# Hint: You will need to create an instance of MinMaxScaler, fit it on the data and transform the data\n",
    "# Separating features and target variable\n",
    "features = titanic_df.drop(\"survived\", axis=1)\n",
    "target = titanic_df[[\"survived\"]]\n",
    "\n",
    "# Scaling the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = pd.DataFrame(scaler.fit_transform(features), columns = features.columns)\n",
    "\n",
    "# Concatenating scaled features with the target variable\n",
    "titanic_df_scaled = pd.concat([scaled_features, target], axis=1)\n",
    "\n",
    "# Split the preprocessed dataset into the training and testing datasets with a 70%-30% split\n",
    "train_data, test_data = train_test_split(titanic_df_scaled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Separate the target variable (\"survived\") from the rest of the training data\n",
    "x_train = train_data.drop(\"survived\", axis=1)\n",
    "y_train = train_data[\"survived\"]\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "# Training the Logistic Regression model\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# Separate the independent (x_test) and dependent (y_test) variables from the testing dataset\n",
    "x_test = test_data.drop(\"survived\", axis=1)\n",
    "y_test = test_data[\"survived\"]\n",
    "\n",
    "# Using the model to make predictions on the testing dataset\n",
    "predictions = logreg.predict(x_test)\n",
    "\n",
    "# Displaying metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  # Changed from precision_score to accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop columns with strings and 'pclass', which is categorical but read as a numeric type\n",
    "titanic_df = titanic_df.select_dtypes(exclude=['object', 'category'])\n",
    "\n",
    "# Handle any NaN values by filling them with the mean of the column (ignoring 'pclass', which is categorical)\n",
    "numeric_columns = titanic_df.columns.drop('pclass')\n",
    "titanic_df[numeric_columns] = titanic_df[numeric_columns].fillna(titanic_df[numeric_columns].mean())\n",
    "\n",
    "# Convert 'pclass' to integer type if it's not already\n",
    "titanic_df['pclass'] = titanic_df['pclass'].astype(int)\n",
    "\n",
    "# TODO: Split the dataset into training and testing sets with a 70%-30% split\n",
    "\n",
    "# TODO: Identify and separate the target variable 'survived' from the training and testing data\n",
    "\n",
    "# TODO: Initialize StandardScaler and scale the features\n",
    "\n",
    "# TODO: Initialize the Logistic Regression model and train it on the scaled training data\n",
    "\n",
    "# TODO: Use the trained model to make predictions on the scaled testing data\n",
    "\n",
    "# TODO: Calculate and print the accuracy score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
