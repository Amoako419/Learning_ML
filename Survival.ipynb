{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (623, 15)\n",
      "Test data shape: (268, 15)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Splitting the full dataset into the training and testing datasets\n",
    "train_data, test_data = train_test_split(titanic_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Printing out the shapes of the datasets\n",
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       111\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       1.00      1.00      1.00       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [  0 111]]\n",
      "Accuracy Score:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# One-hot encode categorical variables using pandas get_dummies\n",
    "titanic_preprocessed = pd.get_dummies(titanic_df, columns=['sex', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'], drop_first=True)\n",
    "\n",
    "# Handle any NaN values by filling them with the mean of the column\n",
    "titanic_preprocessed = titanic_preprocessed.fillna(titanic_preprocessed.mean())\n",
    "\n",
    "# Split the preprocessed dataset into the training and testing datasets with a 70%-30% split\n",
    "train_data, test_data = train_test_split(titanic_preprocessed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Separate the target variable (\"survived\") from the rest of the training data\n",
    "x_train = train_data.drop(\"survived\", axis=1)\n",
    "y_train = train_data[\"survived\"]\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "\n",
    "# Training the Logistic Regression model\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "#The test dataset\n",
    "x_test =test_data.drop(\"survived\", axis=1)\n",
    "y_test = test_data[\"survived\"]\n",
    "\n",
    "# Using the model to make predictions on the testing dataset\n",
    "predictions = logreg.predict(x_test) \n",
    "\n",
    "# Displaying metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions)) \n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))  \n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, predictions))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1216103798.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    WITH MinmaxScaler\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "WITH MinmaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78       157\n",
      "           1       0.74      0.46      0.57       111\n",
      "\n",
      "    accuracy                           0.71       268\n",
      "   macro avg       0.72      0.67      0.67       268\n",
      "weighted avg       0.72      0.71      0.69       268\n",
      "\n",
      "Accuracy Score:\n",
      "0.7089552238805971\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic')\n",
    "\n",
    "# Drop non-numeric columns for simplicity\n",
    "titanic_df = titanic_df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Handle any NaN values by filling them with the mean of the column\n",
    "titanic_df = titanic_df.fillna(titanic_df.mean())\n",
    "\n",
    "# TODO: Use MinMaxScaler to scale the numeric features into a standard range\n",
    "# Hint: You will need to create an instance of MinMaxScaler, fit it on the data and transform the data\n",
    "# Separating features and target variable\n",
    "features = titanic_df.drop(\"survived\", axis=1)\n",
    "target = titanic_df[[\"survived\"]]\n",
    "\n",
    "# Scaling the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = pd.DataFrame(scaler.fit_transform(features), columns = features.columns)\n",
    "\n",
    "# Concatenating scaled features with the target variable\n",
    "titanic_df_scaled = pd.concat([scaled_features, target], axis=1)\n",
    "\n",
    "# Split the preprocessed dataset into the training and testing datasets with a 70%-30% split\n",
    "train_data, test_data = train_test_split(titanic_df_scaled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Separate the target variable (\"survived\") from the rest of the training data\n",
    "x_train = train_data.drop(\"survived\", axis=1)\n",
    "y_train = train_data[\"survived\"]\n",
    "\n",
    "# Initialize a Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)  \n",
    "\n",
    "# Training the Logistic Regression model\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "# Separate the independent (x_test) and dependent (y_test) variables from the testing dataset\n",
    "x_test = test_data.drop(\"survived\", axis=1)\n",
    "y_test = test_data[\"survived\"]\n",
    "\n",
    "# Using the model to make predictions on the testing dataset\n",
    "predictions = logreg.predict(x_test)\n",
    "\n",
    "# Displaying metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:\n",
      "0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = sns.load_dataset('titanic') # Assuming 'titanic.csv' is in the working directory\n",
    "\n",
    "# Drop columns with strings and 'pclass', which is categorical but read as a numeric type\n",
    "titanic_df = titanic_df.select_dtypes(exclude=['object', 'category'])\n",
    "\n",
    "# Handle any NaN values by filling them with the mean of the column (ignoring 'pclass', which is categorical)\n",
    "numeric_columns = titanic_df.columns.drop('pclass')\n",
    "titanic_df[numeric_columns] = titanic_df[numeric_columns].fillna(titanic_df[numeric_columns].mean())\n",
    "\n",
    "# Convert 'pclass' to integer type if it's not already\n",
    "titanic_df['pclass'] = titanic_df['pclass'].astype(int)\n",
    "\n",
    "# Split the dataset into training and testing sets with a 70%-30% split\n",
    "train_data, test_data = train_test_split(titanic_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify and separate the target variable 'survived' from the training and testing data\n",
    "x_train = train_data.drop(\"survived\", axis=1)\n",
    "y_train = train_data[\"survived\"]\n",
    "\n",
    "x_test = test_data.drop(\"survived\", axis=1)\n",
    "y_test = test_data[\"survived\"]\n",
    "\n",
    "# Initialize StandardScaler and scale the features\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Initialize the Logistic Regression model and train it on the scaled training data\n",
    "logreg = LogisticRegression(max_iter=1000)  \n",
    "logreg.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the scaled testing data\n",
    "predictions = logreg.predict(x_test_scaled)\n",
    "\n",
    "# Calculate and print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
